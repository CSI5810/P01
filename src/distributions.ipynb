{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK CATEGOIRES FUNCTION\n",
    "def checkCategorical(data_frame, column, approved_list):\n",
    "    _counts = df[column].value_counts()\n",
    "    not_in_list = 0\n",
    "    for x in _counts.index.tolist():\n",
    "        if x not in approved_list: \n",
    "            print(x)\n",
    "            not_in_list += 1\n",
    "    print('{} {} categories found that were not in the official {} list.'.format(not_in_list, column, column))\n",
    "    print(_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT CONTINUOUS DATA FUNCTION\n",
    "def plotContinuous(data_frame, x, y, marker_size, size):\n",
    "    groups = data_frame.groupby('y')\n",
    "    p = 0\n",
    "    for name, group in groups:\n",
    "        plt.plot(group[x],group[y],marker='.',ms=marker_size[p],linestyle='',label=name)\n",
    "        p += 1\n",
    "    plt.rcParams[\"figure.figsize\"] = (size[0],size[1])\n",
    "    plt.xlabel=x\n",
    "    plt.ylabel=y\n",
    "    plt.legend(prop={'size':20})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP WRAPPER\n",
    "def mlpWrapper(df, mute):\n",
    "    # split into train and test data\n",
    "    if not mute: print('TTT seed value: {}'.format(TTT_seed))\n",
    "    train, test = train_test_split(\n",
    "        df,\n",
    "        test_size=0.2,\n",
    "        random_state=TTT_seed\n",
    "    )\n",
    "    X_train = train[train.columns[:-1]]\n",
    "    X_test = test[test.columns[:-1]]\n",
    "    y_train = train[train.columns[-1]]\n",
    "    y_test = test[test.columns[-1]]\n",
    "\n",
    "    # useful info print out\n",
    "    if not mute: print('training set size: {}'.format(train.shape[0]))\n",
    "    if not mute: print('testing set size: {}'.format(test.shape[0]))\n",
    "\n",
    "    # call training function\n",
    "    if not mute: print('MLP seed value: {}'.format(MLP_seed))\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes=50,\n",
    "        activation='logistic',\n",
    "        learning_rate_init=0.4,\n",
    "        batch_size=100,\n",
    "        solver='sgd',\n",
    "        random_state=MLP_seed,\n",
    "        max_iter=10000\n",
    "    ).fit(X_train,y_train)\n",
    "\n",
    "    # print out results\n",
    "    result = mlp.predict(test[test.columns[:-1]])\n",
    "    result_train = mlp.score(X_train, y_train)\n",
    "    result_test = mlp.score(X_test, y_test)\n",
    "    if not mute: print('Training accuracy: {:.2f}'.format(result_train))\n",
    "    if not mute: print('Testing accuracy: {:.2f}'.format(result_test))\n",
    "\n",
    "    # return\n",
    "    return {'train': result_train, 'test': result_test}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 HOT\n",
    "def oneHot(df, column):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _df = pd.get_dummies(df, columns=[column], prefix=column)\n",
    "    \n",
    "    #return\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT\n",
    "def insert(df, insert_df):\n",
    "    _left = df[df.columns[:-1]]\n",
    "    _right = df[df.columns[-1]]\n",
    "    _final = pd.concat([_left,insert_df,_right],axis=1)\n",
    "    return _final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE FIRST TIME CALLS\n",
    "def removeFirstCalls(df):\n",
    "    _df = df\n",
    "    return _df[_df['pdays']!=999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "import random\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "file_name = '../bank-additional/bank-additional/bank-additional-full.csv'\n",
    "df = pd.read_csv(file_name, sep=';')\n",
    "df = df.drop_duplicates(keep='first')\n",
    "TTT_seed = randint(0,99)\n",
    "MLP_seed = randint(0,99)\n",
    "_ready = {}\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE PDAYS\n",
    "\n",
    "def removePdays(df):\n",
    "    return df.drop('pdays', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP NORMALIZED DATAFRAME \n",
    "\n",
    "def getNormalized(df, remove_pdays):\n",
    "\n",
    "    # selection list for readability\n",
    "    selection = [\n",
    "        'age',\n",
    "        'campaign',\n",
    "        'pdays',\n",
    "        'previous',\n",
    "        'emp.var.rate',\n",
    "        'cons.price.idx',\n",
    "        'cons.conf.idx',\n",
    "        'euribor3m',\n",
    "        'nr.employed',\n",
    "        'y'\n",
    "    ]\n",
    "    if remove_pdays: selection.remove('pdays')\n",
    "\n",
    "    # scrub dataframe: no first selection and no first time subs\n",
    "    _df = df[selection]\n",
    "\n",
    "    # max/min normalization\n",
    "    _norm = _df[_df.columns[:-1]]\n",
    "    _norm = (_norm - _norm.mean()) / (_norm.max() - _norm.min())\n",
    "    \n",
    "    # reassemble\n",
    "    _final = pd.concat([_norm, _df['y']], axis=1)\n",
    "    \n",
    "    #return\n",
    "    return _final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLP ONLY FIRST CALL SUBS\n",
    "\n",
    "# # selection list for readability\n",
    "# selection = [\n",
    "#     'age',\n",
    "#     'duration',\n",
    "#     'campaign',\n",
    "#     'pdays',\n",
    "#     'previous',\n",
    "#     'emp.var.rate',\n",
    "#     'cons.price.idx',\n",
    "#     'cons.conf.idx',\n",
    "#     'euribor3m',\n",
    "#     'nr.employed',\n",
    "#     'y'\n",
    "# ]\n",
    "\n",
    "# # scrub dataframe: no first selection and only first call subs\n",
    "# scrubbed = df[selection]\n",
    "# scrubbed = scrubbed[scrubbed['pdays']==999]\n",
    "\n",
    "# # max/min normalization\n",
    "# norm_df = scrubbed[selection[:-1]]\n",
    "# norm_df = norm_df.loc[:, norm_df.columns != 'pdays']\n",
    "# norm_df = (norm_df-norm_df.mean())/(norm_df.max()-norm_df.min())\n",
    "# final = pd.concat([norm_df,scrubbed['pdays'],scrubbed['y']],axis=1)\n",
    "\n",
    "# # split into train and test data\n",
    "# train,test = train_test_split(final,test_size=0.999, random_state=24)\n",
    "# X_train = train[train.columns[:-1]]\n",
    "# X_test = test[test.columns[:-1]]\n",
    "# y_train = train[train.columns[-1]]\n",
    "# y_test = test[test.columns[-1]]\n",
    "\n",
    "# # useful info print out\n",
    "# print('training set size: {}'.format(train.shape[0]))\n",
    "# print('testing set size: {}'.format(test.shape[0]))\n",
    "\n",
    "# # call training function\n",
    "# mlp = MLPClassifier(\n",
    "#     hidden_layer_sizes=1,\n",
    "#     activation='logistic',\n",
    "#     learning_rate_init=0.04,\n",
    "#     batch_size=10,\n",
    "#     solver='sgd',\n",
    "#     random_state=0,\n",
    "#     max_iter=10000\n",
    "# ).fit(X_train,y_train)\n",
    "\n",
    "# # print out results\n",
    "# result = mlp.predict(test[test.columns[:-1]])\n",
    "# print('Training accuracy: {:.2f}'.format(mlp.score(X_train, y_train)))\n",
    "# print('Testing accuracy: {:.2f}'.format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time calls represented 96% of the total number of calls.\n",
      "87% of the calls were first time calls where the customer declined the offer.\n"
     ]
    }
   ],
   "source": [
    "# THE PROBLEM WITH FIRST TIME CALL DATA\n",
    "counts = df.pdays.value_counts()\n",
    "print('First time calls represented {:.0%} of the total number of calls.'.format(counts.max()/df.shape[0]))\n",
    "no = df[df['y']=='no']\n",
    "counts = no.pdays.value_counts()\n",
    "print('{:.0%} of the calls were first time calls where the customer declined the offer.'.format(counts.max()/df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED JOB\n",
    "\n",
    "def getJob(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _jobs = df['job']\n",
    "    \n",
    "    # print(_jobs.value_counts())\n",
    "    _jobs = oneHot(_jobs, 'job')\n",
    "\n",
    "    # output\n",
    "    # print(_jobs.head())\n",
    "\n",
    "    return _jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED MARITAL\n",
    "\n",
    "def getMarital(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _marital = df['marital']\n",
    "    # print(_marital.value_counts())\n",
    "    _marital = oneHot(_marital, 'marital')\n",
    "    _marital = _marital.drop('marital_unknown',axis=1)\n",
    "\n",
    "    # output\n",
    "    # print(_marital.head())\n",
    "\n",
    "    return _marital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED EDUCATION\n",
    "\n",
    "def getEducation(df):\n",
    "\n",
    "    # replace\n",
    "    _encoded_education = {\n",
    "        'education': {\n",
    "            'unknown': 0/7,\n",
    "            'illiterate': 1/7,\n",
    "            'basic.4y': 2/7,\n",
    "            'basic.6y': 3/7,\n",
    "            'basic.9y': 4/7,\n",
    "            'high.school': 5/7,\n",
    "            'professional.course': 6/7,\n",
    "            'university.degree': 7/7,\n",
    "        }\n",
    "    }\n",
    "    # print(_education.education.value_counts())\n",
    "    _education = df.replace(_encoded_education)\n",
    "    _education = _education.education\n",
    "\n",
    "    # output\n",
    "    # print(_education.head())\n",
    "\n",
    "    return _education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED DEFAULT\n",
    "\n",
    "def getDefault(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _default = df.default\n",
    "    # print(_default.value_counts())\n",
    "    _default = oneHot(_default, 'default')\n",
    "    _default = _default.drop('default_unknown',axis=1)\n",
    "\n",
    "    # output\n",
    "    # print(_default.head())\n",
    "\n",
    "    return _default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED HOUSING\n",
    "\n",
    "def getHousing(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _housing = df.housing\n",
    "    # print(_housing.value_counts())\n",
    "    _housing = oneHot(_housing, 'housing')\n",
    "    _housing = _housing.drop('housing_unknown',axis=1)\n",
    "\n",
    "    # output\n",
    "    # print(_housing.head())\n",
    "\n",
    "    return _housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED LOAN\n",
    "\n",
    "def getLoan(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _loan = df.loan\n",
    "    # print(_loan.value_counts())\n",
    "    _loan = oneHot(_loan, 'loan')\n",
    "    _loan = _loan.drop('loan_unknown',axis=1)\n",
    "\n",
    "    # output\n",
    "    # print(_loan.head())\n",
    "\n",
    "    # return\n",
    "    return _loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED CONTACT\n",
    "\n",
    "def getContact(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _contact = df.contact\n",
    "    # print(_contact.value_counts())\n",
    "    _contact = oneHot(_contact, 'contact')\n",
    "\n",
    "    # output\n",
    "    # print(_contact.head())\n",
    "\n",
    "    # return\n",
    "    return _contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED MONTH\n",
    "\n",
    "def getMonth(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _month = df.month\n",
    "    # print(_month.value_counts())\n",
    "    _month = oneHot(_month, 'month')\n",
    "\n",
    "    # output\n",
    "    # print(_month.head())\n",
    "\n",
    "    # return\n",
    "    return _month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED DAY OF WEEK\n",
    "\n",
    "def getDayOfWeek(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _day_of_week = df.day_of_week\n",
    "    # print(_day_of_week.value_counts())\n",
    "    _day_of_week = oneHot(_day_of_week, 'day_of_week')\n",
    "\n",
    "    # output\n",
    "    # print(_day_of_week.head())\n",
    "\n",
    "    # return\n",
    "    return _day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP ENCODED PREVIOUS OUTCOME\n",
    "\n",
    "def getPoutcome(df):\n",
    "\n",
    "    # 1 hot encoding\n",
    "    _poutcome = df.poutcome\n",
    "    # print(_poutcome.value_counts())\n",
    "    _poutcome = oneHot(_poutcome, 'poutcome')\n",
    "\n",
    "    # output\n",
    "    # print(_poutcome.head())\n",
    "\n",
    "    # return\n",
    "    return _poutcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD ENCODED DATA\n",
    "def assembleData(normalized, ready):\n",
    "    all_data = normalized\n",
    "    for key in ready:\n",
    "        if key != 'normalized':\n",
    "            # print('adding {}...'.format(key))\n",
    "            all_data = insert(all_data, ready[key])\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASEMBLE DATA\n",
    "\n",
    "def assembleReady(df, remove_first_call, remove_pdays):\n",
    "    ready = {}\n",
    "    if remove_first_call and not remove_pdays: _df = removeFirstCalls(df)\n",
    "    if not remove_first_call and remove_pdays: _df = removePdays(df)\n",
    "    if not remove_first_call and not remove_pdays: _df = df\n",
    "    ready['normalized'] = getNormalized(_df, remove_pdays)\n",
    "    ready['job'] = getJob(_df)\n",
    "    ready['marital'] = getMarital(_df)\n",
    "    ready['education'] = getEducation(_df) \n",
    "    ready['default'] = getDefault(_df)\n",
    "    ready['housing'] = getHousing(_df)\n",
    "    ready['loan'] = getLoan(_df)\n",
    "    ready['contact'] = getContact(_df)\n",
    "    ready['month'] = getMonth(_df)\n",
    "    ready['day_of_week'] = getDayOfWeek(_df)\n",
    "    ready['poutcome'] = getPoutcome(_df)\n",
    "    return ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1515, 12)\n",
      "(1515, 3)\n",
      "(1515,)\n",
      "(1515, 1)\n",
      "(1515, 2)\n",
      "(1515, 2)\n",
      "(1515, 2)\n",
      "(1515, 10)\n",
      "(1515, 5)\n",
      "(1515, 2)\n",
      "running test 1\n",
      "0.6006600660066006\n",
      "0.5858085808580858\n"
     ]
    }
   ],
   "source": [
    "# RUN 100 TIMES AND SAVE RESULTS\n",
    "_all_runs = []\n",
    "_ready = assembleReady(df, True, False)\n",
    "_all_data = assembleData(_ready['normalized'], _ready)\n",
    "for _i in range(100):\n",
    "    if _i % 10 == 0: print('running test {}'.format(_i+1))\n",
    "    _this_run = {}\n",
    "    random.seed()\n",
    "    TTT_seed = randint(0,99)\n",
    "    MLP_seed = randint(0,99)\n",
    "    _this_run['TTT_seed'] = TTT_seed\n",
    "    _this_run['MLP_seed'] = MLP_seed\n",
    "    _results = mlpWrapper(_ready['normalized'], True)\n",
    "    _this_run['normalized_train'] = _results['train']\n",
    "    _this_run['normalized_test'] = _results['test']\n",
    "    _results = mlpWrapper(_all_data, True)\n",
    "    _this_run['all_train'] = _results['train']\n",
    "    _this_run['all_test'] = _results['test']\n",
    "    _all_runs.append(_this_run)\n",
    "all_runs_df = pd.DataFrame(_all_runs)\n",
    "# TEST RESULTS\n",
    "print(all_runs_df.normalized_test.mean())\n",
    "print(all_runs_df.all_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41176, 21)\n",
      "(41176, 12)\n",
      "(41176, 3)\n",
      "(41176,)\n",
      "(41176, 2)\n",
      "(41176, 2)\n",
      "(41176, 2)\n",
      "(41176, 2)\n",
      "(41176, 10)\n",
      "(41176, 5)\n",
      "(41176, 3)\n",
      "running test 1\n",
      "0.8898130160271978\n",
      "0.6287128712871287\n"
     ]
    }
   ],
   "source": [
    "# RUN 100 TIMES AND SAVE RESULTS\n",
    "_all_runs = []\n",
    "_ready = assembleReady(df, False, True)\n",
    "all_data = assembleData(_ready['normalized'], _ready)\n",
    "for _i in range(2):\n",
    "    if _i % 10 == 0: print('running test {}'.format(_i+1))\n",
    "    _this_run = {}\n",
    "    random.seed()\n",
    "    TTT_seed = randint(0,99)\n",
    "    MLP_seed = randint(0,99)\n",
    "    _this_run['TTT_seed'] = TTT_seed\n",
    "    _this_run['MLP_seed'] = MLP_seed\n",
    "    _results = mlpWrapper(_ready['normalized'], True)\n",
    "    _this_run['normalized_train'] = _results['train']\n",
    "    _this_run['normalized_test'] = _results['test']\n",
    "    _results = mlpWrapper(_all_data, True)\n",
    "    _this_run['all_train'] = _results['train']\n",
    "    _this_run['all_test'] = _results['test']\n",
    "    _all_runs.append(_this_run)\n",
    "all_runs_df = pd.DataFrame(_all_runs)\n",
    "# TEST RESULTS\n",
    "print(all_runs_df.normalized_test.mean())\n",
    "print(all_runs_df.all_test.mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afe3a465e38fa0b08d26d57982d956da22b8d2ef6c02c05a94dfbea3c184e6d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
